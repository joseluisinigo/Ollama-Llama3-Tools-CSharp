using System;
using System.Net.Http;
using System.Text;
using System.Text.Json;
using System.Threading.Tasks;
using Serilog;

namespace Models
{
    public abstract class OllamaModelBase
    {
        protected static readonly HttpClient client = new HttpClient();

        public virtual async Task HandleRequestAsync(string model)
        {
            // Implementaci√≥n base vac√≠a o mensaje de advertencia
            Log.Warning("‚ö†Ô∏è No se ha implementado HandleRequestAsync en la subclase.");
        }

        public virtual async Task HandleRequestAsync(string model, string? toolName)
        {
            // Implementaci√≥n base para herramientas
            Log.Warning("‚ö†Ô∏è No se ha implementado HandleRequestAsync con herramientas en la subclase.");
        }

        protected async Task<string> SendRequestAsync(string model, object requestBody)
{
    string jsonContent = JsonSerializer.Serialize(requestBody);

    // üîç VERIFICACI√ìN: Imprimir qu√© modelo se est√° enviando en la petici√≥n
    Log.Information($"üì° Enviando solicitud a Ollama: Modelo = {model}, RequestBody = {jsonContent}");

    var content = new StringContent(jsonContent, Encoding.UTF8, "application/json");

    try
    {
        var response = await client.PostAsync("http://localhost:11434/api/chat", content);
        string responseText = await response.Content.ReadAsStringAsync();

        // üîç VERIFICACI√ìN: Confirmar que la respuesta es del modelo correcto
        Log.Information($"üì© Respuesta de Ollama ({model}): {responseText}");

        return responseText;
    }
    catch (Exception ex)
    {
        Log.Error("‚ùå Error en la solicitud a Ollama: {error}", ex.Message);
        return string.Empty;
    }
}

    }
}
